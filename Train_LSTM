import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import OneHotEncoder

from keras.layers import LSTM, Dense, Dropout
from keras.models import Sequential

from sklearn.model_selection import train_test_split

# Đọc dữ liệu
boxing_df = pd.read_csv("BOXING.txt")
hand_clapping_df = pd.read_csv("HANDCLAPPING.txt")
hand_waving_df = pd.read_csv("HANDWAVING.txt")
running_df = pd.read_csv("RUNING.txt")
jogging_df = pd.read_csv("JOGGING.txt")
walking_df = pd.read_csv("WALKING.txt")

X = []
y = []
no_of_timesteps = 10

# data boxing
dataset = boxing_df.iloc[:, 1:].values
n_sample = len(dataset)
for i in range(no_of_timesteps, n_sample):
    X.append(dataset[i - no_of_timesteps:i, :])
    y.append([1, 0, 0, 0, 0, 0])

# data hand clapping
dataset = hand_clapping_df.iloc[:, 1:].values
n_sample = len(dataset)
for i in range(no_of_timesteps, n_sample):
    X.append(dataset[i - no_of_timesteps:i, :])
    y.append([0, 1, 0, 0, 0, 0])

# data hand waving
dataset = hand_waving_df.iloc[:, 1:].values
n_sample = len(dataset)
for i in range(no_of_timesteps, n_sample):
    X.append(dataset[i - no_of_timesteps:i, :])
    y.append([0, 0, 1, 0, 0, 0])

# data running
dataset = running_df.iloc[:, 1:].values
n_sample = len(dataset)
for i in range(no_of_timesteps, n_sample):
    X.append(dataset[i - no_of_timesteps:i, :])
    y.append([0, 0, 0, 1, 0, 0])

# data jogging
dataset = jogging_df.iloc[:, 1:].values
n_sample = len(dataset)
for i in range(no_of_timesteps, n_sample):
    X.append(dataset[i - no_of_timesteps:i, :])
    y.append([0, 0, 0, 0, 1, 0])

# data walking
dataset = walking_df.iloc[:, 1:].values
n_sample = len(dataset)
for i in range(no_of_timesteps, n_sample):
    X.append(dataset[i - no_of_timesteps:i, :])
    y.append([0, 0, 0, 0, 0, 1])

X, y = np.array(X), np.array(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=6, activation="softmax"))
model.compile(optimizer="adam", metrics=['acc'], loss="categorical_crossentropy")

history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_test, y_test))

model.save("model.h5")

# plot acc, loss
#  "Accuracy"
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

# "Loss"
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
